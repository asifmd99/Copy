import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.ws.client.core.WebServiceTemplate;
import org.springframework.ws.transport.http.HttpComponentsMessageSender;

@Configuration
public class SoapClientConfig {

    @Bean
    public WebServiceTemplate webServiceTemplate() {
        WebServiceTemplate webServiceTemplate = new WebServiceTemplate();
        webServiceTemplate.setDefaultUri("http://example.com/your-soap-api-endpoint");
        webServiceTemplate.setMessageSender(httpComponentsMessageSender());
        return webServiceTemplate;
    }

    @Bean
    public HttpComponentsMessageSender httpComponentsMessageSender() {
        return new HttpComponentsMessageSender();
    }
}

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.ws.client.core.WebServiceTemplate;
import example.com.your.generated.package.YourRequestClass;
import example.com.your.generated.package.YourResponseClass;

@Service
public class SoapClientService {

    @Autowired
    private WebServiceTemplate webServiceTemplate;

    public YourResponseClass callSoapService(YourRequestClass request) {
        return (YourResponseClass) webServiceTemplate.marshalSendAndReceive(request);
    }
}
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;
import example.com.your.generated.package.YourRequestClass;
import example.com.your.generated.package.YourResponseClass;

@Service
public class KafkaConsumerService {

    @Autowired
    private SoapClientService soapClientService;

    @KafkaListener(topics = "your_topic", groupId = "group_id", containerFactory = "kafkaListenerContainerFactory")
    public void consume(UserMessage message) {
        // Create a request object for the SOAP service
        YourRequestClass request = new YourRequestClass();
        // Populate the request object using the message fields
        request.setSomeField(message.getSomeField());

        // Call the SOAP service
        YourResponseClass response = soapClientService.callSoapService(request);

        // Merge the response into the UserMessage object
        message.setResponseField(response.getResponseField());

        // Process the updated UserMessage object as needed
        processUserMessage(message);
    }

    private void processUserMessage(UserMessage message) {
        // Implement your processing logic here
    }
}


---------------HOw to configure kafka  for multiple type of  serialiser deserialiser
Understand grouping in kafka consumer 
---------------Flow ----------
 AdminClientConfig values: 
kafka commid id stuff
consumerconfig values
Group was my group - client.id = consumer-myGroup-1
Kafka commiitid,consumerconfig
-------------------------------------
Delete zip  delete .idea files 
--------------------------- 1--------------------------
Remove kafka--  - Create a new file  without mongo Example - class account and site class
                -  Test soap url - how to put headers in place
                -  directly store to mongoDb 
                -  Check if its working
                -  Integrate kafka
------------------------2---------------------
Check week3day4 updated on week5day2 

--------------------------------------------

Create 5 test files - one with kafka example and other without kafka Example  no mongodb in both
----------------------------------------
Try checking for making configuration of both kafka Producer and consumer,
---------------------------------------
if nothing works delete Gradle  file then Restartv
-----------------------------------
Where to integrate kafka Streams
-----------------------------------------------------------------------------------------------------------------------------
how groupid in kafka consumer works what will happen if 2 kafka listener listening to same topic with same group id and function parameters
Key Points
Parallel Consumption: The two listeners (listen1 and listen2) will consume messages in parallel, each handling different partitions of the topic.
No Message Duplication: Each message will be consumed by only one of the listeners, ensuring no duplication within the consumer group.
Load Balancing: Kafka will balance the load between the two listeners, distributing the partitions equally (as much as possible).
Fault Tolerance: If one listener stops, the remaining listener will take over its partitions, ensuring continuous message consumption.

--------------------------------------------------------------------------------------------------------------------------
if 2 differenet function parameter same topic same group
 create a custom deserialiser class 
import org.apache.kafka.common.serialization.Deserializer;
import com.fasterxml.jackson.databind.ObjectMapper;

import java.util.Map;

public class CustomDeserializer implements Deserializer<Object> {

    private final ObjectMapper objectMapper = new ObjectMapper();

    @Override
    public void configure(Map<String, ?> configs, boolean isKey) {
        // Configure the deserializer if needed
    }

    @Override
    public Object deserialize(String topic, byte[] data) {
        try {
            // Deserialize based on some logic, such as a class type indicator
            String content = new String(data);
            if (content.startsWith("{")) {
                // Assuming JSON object, change MyClass to your target class
                return objectMapper.readValue(data, MyClass.class);
            } else {
                return content;
            }
        } catch (Exception e) {
            throw new RuntimeException("Error deserializing message", e);
        }
    }

    @Override
    public void close() {
        // Close resources if needed
    }
}
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class KafkaConsumerConfig {

    private final String bootstrapServers = "localhost:9092";
    private final String groupId = "my-group-id";

    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, CustomDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}

Behavior of Kafka Listeners with Different Parameters
Message Handling:

Each listener will receive messages according to the deserialization logic.
listenWithString will receive messages that can be deserialized into a String.
listenWithObject will receive messages that can be deserialized into MyClass.
When Kafka listeners have different function parameters but share the same group.id, they will consume messages from the same topic based on the partition assignment by Kafka. Each listener will handle messages according to its deserialization logic and expected parameter type. Proper configuration of deserialization and message format is essential to ensure that each listener can process the messages it receives.


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
for 2 types of object in kafka consumer

ChatGPT
To handle multiple types of objects in a Kafka consumer, you can implement a dynamic deserialization strategy that differentiates between the types of messages based on some metadata (like headers) or content structure. Hereâ€™s how you can achieve this in a Spring Boot application using Apache Kafka:
